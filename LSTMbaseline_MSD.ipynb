{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Utilities\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "# batch_size = 500\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "batch_size = 128\n",
    "from mlp.data_providers import MSD10GenreDataProvider, MSD25GenreDataProvider\n",
    "train_data = MSD10GenreDataProvider('train', batch_size = batch_size, max_num_batches=5)\n",
    "valid_data = MSD10GenreDataProvider('valid', batch_size = batch_size, max_num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "# training_iters = 100000\n",
    "training_epochs = 50\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 25 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 120 # timesteps\n",
    "n_hidden = 50 # dim(hidden layer)\n",
    "n_layers = 5 # number of layers in cell\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "tf.add_to_collection('vars', weights['out'])\n",
    "tf.add_to_collection('vars', biases['out'])\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def LSTM(x, weights, biases): # Fully BPTT\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    lstm_cell = tf.nn.rnn_cell.MultiRNNCell(cells=[lstm_cell] * n_layers, state_is_tuple=True)\n",
    "    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    # [outputs' size is (?, n_steps, n_hidden), we want the last element, with index 120-1 for MSD\n",
    "    # size of last_output is then (?, n_hidden)\n",
    "    \n",
    "#     print 'state_size = ', lstm_cell.state_size\n",
    "    \n",
    "    last_output = outputs[:, outputs.get_shape()[1] - 1, :]\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(last_output, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = LSTM(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performance pickles\n",
    "err_tr = np.zeros(training_epochs)\n",
    "acc_tr = np.zeros(training_epochs)\n",
    "err_val = np.zeros(training_epochs)\n",
    "acc_val = np.zeros(training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Starts! Dim(hidden)=50\n",
      "End of epoch 01: err(train)=1.91 acc(train)=0.32 ,,, taking 17.1(sec)\n",
      "                 err(valid)=1.72 acc(valid)=0.38 ,,, taking 1.1(sec) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ba588ec89fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             _, batch_error, batch_acc = sess.run(\n\u001b[1;32m     19\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 feed_dict={x: input_batch, y: target_batch})\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mrunning_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mrunning_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"Optimization Starts! Dim(hidden)={0:d}\".format(n_hidden))\n",
    "    sess.run(init) #initial run\n",
    "        \n",
    "    for e in range(training_epochs):                              \n",
    "        if e == 0:\n",
    "            start = time.time()\n",
    "            num_batches_tr = 0\n",
    "            num_batches_val = 0\n",
    "\n",
    "        running_error = 0.\n",
    "        running_accuracy = 0.\n",
    "        for input_batch, target_batch in train_data:\n",
    "            if e == 0:\n",
    "                num_batches_tr += 1\n",
    "            input_batch = input_batch.reshape((batch_size,n_steps,n_input))\n",
    "\n",
    "            _, batch_error, batch_acc = sess.run(\n",
    "                [optimizer, cost, accuracy], \n",
    "                feed_dict={x: input_batch, y: target_batch})\n",
    "            running_error += batch_error\n",
    "            running_accuracy += batch_acc\n",
    "#             if num_batches_tr % 100 == 0:\n",
    "#                 print('{0:02d}th batch: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "#                       .format(num_batches_tr,running_error/num_batches_tr,running_accuracy/num_batches_tr))                      \n",
    "        running_error /= num_batches_tr\n",
    "        err_tr[e] = running_error\n",
    "        running_accuracy /= num_batches_tr\n",
    "        acc_tr[e] = running_accuracy\n",
    "\n",
    "        if ((e+1) % display_step == 0) or (e == 0):\n",
    "            end = time.time()\n",
    "            print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f} ,,, taking {3:.1f}(sec)'\n",
    "                  .format(e + 1, running_error, running_accuracy, end-start))\n",
    "\n",
    "            start = time.time()            \n",
    "\n",
    "            valid_error = 0.\n",
    "            valid_accuracy = 0.\n",
    "            for input_batch, target_batch in valid_data:\n",
    "                if e == 0:\n",
    "                    num_batches_val += 1\n",
    "                input_batch = input_batch.reshape((batch_size,n_steps,n_input))\n",
    "\n",
    "                batch_error, batch_acc = sess.run(\n",
    "                    [cost, accuracy], \n",
    "                    feed_dict={x: input_batch, y: target_batch})\n",
    "                valid_error += batch_error\n",
    "                valid_accuracy += batch_acc\n",
    "            valid_error /= num_batches_val\n",
    "            err_val[e] = valid_error\n",
    "            valid_accuracy /= num_batches_val\n",
    "            acc_val[e] = valid_accuracy\n",
    "\n",
    "            end = time.time()\n",
    "            print('                 err(valid)={0:.2f} acc(valid)={1:.2f} ,,, taking {2:.1f}(sec) '\n",
    "                   .format(valid_error, valid_accuracy, end-start))\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "    sname = 'params_lstm_h' + str(n_hidden) +'_ly' + str(n_layers)\n",
    "    saver.save(sess, sname)\n",
    "\n",
    "    lstm_prf = {\"err_tr\": err_tr, \"err_val\": err_val, \"acc_tr\": acc_tr, \"acc_val\": acc_val}\n",
    "    fname = \"lstm_performances_h\" + str(n_hidden) +'_ly' + str(n_layers) + \".p\"\n",
    "    pickle.dump(lstm_prf, open(fname,\"wb\"))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference: \n",
    "(n_hidden, time(sec)_tr) per epoch: (10,17.1) (30,30.5) (50,49.5) (100,77.9) (200,171.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Restored> Optimization Starts! Dim(hidden)=5\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"<Restored> Optimization Starts! Dim(hidden)={0:d}\".format(n_hidden))\n",
    "    new_saver = tf.train.import_meta_graph('params_lstm_h5.meta')\n",
    "    new_saver.restore(sess_saved, tf.train.latest_checkpoint('./'))\n",
    "    \n",
    "    vars_saved = tf.get_collection('vars')\n",
    "    \n",
    "    sess.run(init)    \n",
    "    for e in range(training_epochs):                      \n",
    "        if e == 0:\n",
    "            start = time.time()\n",
    "            num_batches_tr = 0\n",
    "            num_batches_val = 0\n",
    "\n",
    "        running_error = 0.\n",
    "        running_accuracy = 0.\n",
    "        for input_batch, target_batch in train_data:\n",
    "            if e == 0:\n",
    "                num_batches_tr += 1\n",
    "            input_batch = input_batch.reshape((batch_size,n_steps,n_input))\n",
    "\n",
    "            _, batch_error, batch_acc = sess.run(\n",
    "                [optimizer, cost, accuracy], \n",
    "                feed_dict={x: input_batch, y: target_batch})\n",
    "            running_error += batch_error\n",
    "            running_accuracy += batch_acc\n",
    "#             if num_batches_tr % 100 == 0:\n",
    "#                 print('{0:02d}th batch: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "#                       .format(num_batches_tr,running_error/num_batches_tr,running_accuracy/num_batches_tr))                      \n",
    "        running_error /= num_batches_tr\n",
    "        err_tr[e] = running_error\n",
    "        running_accuracy /= num_batches_tr\n",
    "        acc_tr[e] = running_accuracy\n",
    "\n",
    "        if ((e+1) % display_step == 0) or (e == 0):\n",
    "            end = time.time()\n",
    "            print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f} ,,, taking {3:.1f}(sec)'\n",
    "                  .format(e + 1, running_error, running_accuracy, end-start))\n",
    "\n",
    "            start = time.time()            \n",
    "\n",
    "            valid_error = 0.\n",
    "            valid_accuracy = 0.\n",
    "            for input_batch, target_batch in valid_data:\n",
    "                if e == 0:\n",
    "                    num_batches_val += 1\n",
    "                input_batch = input_batch.reshape((batch_size,n_steps,n_input))\n",
    "\n",
    "                batch_error, batch_acc = sess.run(\n",
    "                    [cost, accuracy], \n",
    "                    feed_dict={x: input_batch, y: target_batch})\n",
    "                valid_error += batch_error\n",
    "                valid_accuracy += batch_acc\n",
    "            valid_error /= num_batches_val\n",
    "            err_val[e] = valid_error\n",
    "            valid_accuracy /= num_batches_val\n",
    "            acc_val[e] = valid_accuracy\n",
    "\n",
    "            end = time.time()\n",
    "            print('                 err(valid)={0:.2f} acc(valid)={1:.2f} ,,, taking {2:.1f}(sec) '\n",
    "                   .format(valid_error, valid_accuracy, end-start))\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "    sname = 'params_lstm_h' + str(n_hidden)\n",
    "    saver.save(sess, sname)\n",
    "\n",
    "    lstm_prf = {\"err_tr\": err_tr, \"err_val\": err_val, \"acc_tr\": acc_tr, \"acc_val\": acc_val}\n",
    "    fname = \"lstm_performances_h\" + str(n_hidden) + \".p\"\n",
    "    pickle.dump(lstm_prf, open(fname,\"wb\"))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Worked for 1 epoch then Iter stopped ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000, Minibatch Loss= 2.541809, Training Accuracy= 0.32000\n",
      "Iter 2000, Minibatch Loss= 2.333999, Training Accuracy= 0.27000\n",
      "Iter 3000, Minibatch Loss= 1.916845, Training Accuracy= 0.37000\n",
      "Iter 4000, Minibatch Loss= 1.882300, Training Accuracy= 0.37000\n",
      "Iter 5000, Minibatch Loss= 1.661882, Training Accuracy= 0.45000\n",
      "Iter 6000, Minibatch Loss= 1.590190, Training Accuracy= 0.44000\n",
      "Iter 7000, Minibatch Loss= 1.780682, Training Accuracy= 0.36000\n",
      "Iter 8000, Minibatch Loss= 1.716225, Training Accuracy= 0.43000\n",
      "Iter 9000, Minibatch Loss= 1.640091, Training Accuracy= 0.40000\n",
      "Iter 10000, Minibatch Loss= 1.656243, Training Accuracy= 0.37000\n",
      "Iter 11000, Minibatch Loss= 1.606353, Training Accuracy= 0.46000\n",
      "Iter 12000, Minibatch Loss= 1.530744, Training Accuracy= 0.48000\n",
      "Iter 13000, Minibatch Loss= 1.729684, Training Accuracy= 0.37000\n",
      "Iter 14000, Minibatch Loss= 1.772618, Training Accuracy= 0.42000\n",
      "Iter 15000, Minibatch Loss= 1.725407, Training Accuracy= 0.40000\n",
      "Iter 16000, Minibatch Loss= 1.633636, Training Accuracy= 0.39000\n",
      "Iter 17000, Minibatch Loss= 1.736777, Training Accuracy= 0.42000\n",
      "Iter 18000, Minibatch Loss= 1.686890, Training Accuracy= 0.38000\n",
      "Iter 19000, Minibatch Loss= 1.658400, Training Accuracy= 0.42000\n",
      "Iter 20000, Minibatch Loss= 1.674387, Training Accuracy= 0.41000\n",
      "Iter 21000, Minibatch Loss= 1.823683, Training Accuracy= 0.32000\n",
      "Iter 22000, Minibatch Loss= 1.558752, Training Accuracy= 0.48000\n",
      "Iter 23000, Minibatch Loss= 1.739689, Training Accuracy= 0.32000\n",
      "Iter 24000, Minibatch Loss= 1.544780, Training Accuracy= 0.42000\n",
      "Iter 25000, Minibatch Loss= 1.552504, Training Accuracy= 0.44000\n",
      "Iter 26000, Minibatch Loss= 1.696384, Training Accuracy= 0.39000\n",
      "Iter 27000, Minibatch Loss= 1.561974, Training Accuracy= 0.47000\n",
      "Iter 28000, Minibatch Loss= 1.659296, Training Accuracy= 0.45000\n",
      "Iter 29000, Minibatch Loss= 1.569666, Training Accuracy= 0.46000\n",
      "Iter 30000, Minibatch Loss= 1.520800, Training Accuracy= 0.51000\n",
      "Iter 31000, Minibatch Loss= 1.510392, Training Accuracy= 0.51000\n",
      "Iter 32000, Minibatch Loss= 1.443846, Training Accuracy= 0.52000\n",
      "Iter 33000, Minibatch Loss= 1.593562, Training Accuracy= 0.39000\n",
      "Iter 34000, Minibatch Loss= 1.540859, Training Accuracy= 0.46000\n",
      "Iter 35000, Minibatch Loss= 1.401352, Training Accuracy= 0.56000\n",
      "Iter 36000, Minibatch Loss= 1.605527, Training Accuracy= 0.46000\n",
      "Iter 37000, Minibatch Loss= 1.390259, Training Accuracy= 0.52000\n",
      "Iter 38000, Minibatch Loss= 1.482658, Training Accuracy= 0.48000\n",
      "Iter 39000, Minibatch Loss= 1.447600, Training Accuracy= 0.54000\n",
      "Iter 40000, Minibatch Loss= 1.594065, Training Accuracy= 0.41000\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-29f55a9a5e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         batch_x, batch_y = mnist.train.next_batch(batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Reshape data to get 28 seq of 28 elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/mlpractical/mlp/data_providers.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;34m\"\"\"Returns next data batch or raises `StopIteration` if at end.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOneOfKDataProvider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_one_of_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/mlpractical/mlp/data_providers.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# new epoch ready for another pass and indicate iteration is at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;31m# create an index slice corresponding to current batch number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         batch_slice = slice(self._curr_batch * self.batch_size,\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "#         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x, batch_y = train_data.next()\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1000, Minibatch Loss= 1.858730, Training Accuracy= 0.39000\n",
      "Iter 2000, Minibatch Loss= 1.406672, Training Accuracy= 0.50000\n",
      "Iter 3000, Minibatch Loss= 1.266393, Training Accuracy= 0.53000\n",
      "Iter 4000, Minibatch Loss= 0.981411, Training Accuracy= 0.72000\n",
      "Iter 5000, Minibatch Loss= 0.846963, Training Accuracy= 0.75000\n",
      "Iter 6000, Minibatch Loss= 0.874808, Training Accuracy= 0.71000\n",
      "Iter 7000, Minibatch Loss= 0.574552, Training Accuracy= 0.83000\n",
      "Iter 8000, Minibatch Loss= 0.729932, Training Accuracy= 0.74000\n",
      "Iter 9000, Minibatch Loss= 0.985042, Training Accuracy= 0.72000\n",
      "Iter 10000, Minibatch Loss= 0.505130, Training Accuracy= 0.85000\n",
      "Iter 11000, Minibatch Loss= 0.529583, Training Accuracy= 0.85000\n",
      "Iter 12000, Minibatch Loss= 0.463187, Training Accuracy= 0.84000\n",
      "Iter 13000, Minibatch Loss= 0.344254, Training Accuracy= 0.90000\n",
      "Iter 14000, Minibatch Loss= 0.333179, Training Accuracy= 0.91000\n",
      "Iter 15000, Minibatch Loss= 0.350638, Training Accuracy= 0.89000\n",
      "Iter 16000, Minibatch Loss= 0.639187, Training Accuracy= 0.79000\n",
      "Iter 17000, Minibatch Loss= 0.287978, Training Accuracy= 0.91000\n",
      "Iter 18000, Minibatch Loss= 0.180911, Training Accuracy= 0.95000\n",
      "Iter 19000, Minibatch Loss= 0.395561, Training Accuracy= 0.90000\n",
      "Iter 20000, Minibatch Loss= 0.302618, Training Accuracy= 0.87000\n",
      "Iter 21000, Minibatch Loss= 0.263321, Training Accuracy= 0.88000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cd4728047a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Calculate batch accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Calculate accuracy for 128 mnist test images\n",
    "# test_len = 100\n",
    "# test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "# test_label = mnist.test.labels[:test_len]\n",
    "# print(\"Testing Accuracy:\", \\\n",
    "#     sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST works in below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1280, Minibatch Loss= 1.745764, Training Accuracy= 0.37500\n",
      "Iter 2560, Minibatch Loss= 1.635502, Training Accuracy= 0.48438\n",
      "Iter 3840, Minibatch Loss= 1.253110, Training Accuracy= 0.57812\n",
      "Iter 5120, Minibatch Loss= 0.925527, Training Accuracy= 0.64844\n",
      "Iter 6400, Minibatch Loss= 0.760226, Training Accuracy= 0.71094\n",
      "Iter 7680, Minibatch Loss= 1.037197, Training Accuracy= 0.64062\n",
      "Iter 8960, Minibatch Loss= 0.818278, Training Accuracy= 0.75000\n",
      "Iter 10240, Minibatch Loss= 0.589991, Training Accuracy= 0.83594\n",
      "Iter 11520, Minibatch Loss= 0.358511, Training Accuracy= 0.92188\n",
      "Iter 12800, Minibatch Loss= 0.640873, Training Accuracy= 0.78125\n",
      "Iter 14080, Minibatch Loss= 0.490448, Training Accuracy= 0.82812\n",
      "Iter 15360, Minibatch Loss= 0.262663, Training Accuracy= 0.96094\n",
      "Iter 16640, Minibatch Loss= 0.388416, Training Accuracy= 0.89844\n",
      "Iter 17920, Minibatch Loss= 0.267542, Training Accuracy= 0.89844\n",
      "Iter 19200, Minibatch Loss= 0.240072, Training Accuracy= 0.93750\n",
      "Iter 20480, Minibatch Loss= 0.160020, Training Accuracy= 0.95312\n",
      "Iter 21760, Minibatch Loss= 0.437153, Training Accuracy= 0.84375\n",
      "Iter 23040, Minibatch Loss= 0.158976, Training Accuracy= 0.95312\n",
      "Iter 24320, Minibatch Loss= 0.336228, Training Accuracy= 0.89062\n",
      "Iter 25600, Minibatch Loss= 0.409988, Training Accuracy= 0.87500\n",
      "Iter 26880, Minibatch Loss= 0.200588, Training Accuracy= 0.96094\n",
      "Iter 28160, Minibatch Loss= 0.285090, Training Accuracy= 0.90625\n",
      "Iter 29440, Minibatch Loss= 0.264246, Training Accuracy= 0.91406\n",
      "Iter 30720, Minibatch Loss= 0.210074, Training Accuracy= 0.92188\n",
      "Iter 32000, Minibatch Loss= 0.215899, Training Accuracy= 0.92969\n",
      "Iter 33280, Minibatch Loss= 0.203252, Training Accuracy= 0.92188\n",
      "Iter 34560, Minibatch Loss= 0.180291, Training Accuracy= 0.93750\n",
      "Iter 35840, Minibatch Loss= 0.186640, Training Accuracy= 0.93750\n",
      "Iter 37120, Minibatch Loss= 0.237868, Training Accuracy= 0.91406\n",
      "Iter 38400, Minibatch Loss= 0.153308, Training Accuracy= 0.92969\n",
      "Iter 39680, Minibatch Loss= 0.142200, Training Accuracy= 0.96094\n",
      "Iter 40960, Minibatch Loss= 0.313818, Training Accuracy= 0.86719\n",
      "Iter 42240, Minibatch Loss= 0.118652, Training Accuracy= 0.96875\n",
      "Iter 43520, Minibatch Loss= 0.143747, Training Accuracy= 0.95312\n",
      "Iter 44800, Minibatch Loss= 0.191007, Training Accuracy= 0.93750\n",
      "Iter 46080, Minibatch Loss= 0.069603, Training Accuracy= 0.98438\n",
      "Iter 47360, Minibatch Loss= 0.229739, Training Accuracy= 0.92188\n",
      "Iter 48640, Minibatch Loss= 0.224615, Training Accuracy= 0.92969\n",
      "Iter 49920, Minibatch Loss= 0.214621, Training Accuracy= 0.89844\n",
      "Iter 51200, Minibatch Loss= 0.107089, Training Accuracy= 0.96875\n",
      "Iter 52480, Minibatch Loss= 0.135281, Training Accuracy= 0.94531\n",
      "Iter 53760, Minibatch Loss= 0.054950, Training Accuracy= 0.98438\n",
      "Iter 55040, Minibatch Loss= 0.174364, Training Accuracy= 0.95312\n",
      "Iter 56320, Minibatch Loss= 0.168029, Training Accuracy= 0.93750\n",
      "Iter 57600, Minibatch Loss= 0.109447, Training Accuracy= 0.96875\n",
      "Iter 58880, Minibatch Loss= 0.196220, Training Accuracy= 0.96094\n",
      "Iter 60160, Minibatch Loss= 0.165621, Training Accuracy= 0.93750\n",
      "Iter 61440, Minibatch Loss= 0.097682, Training Accuracy= 0.96094\n",
      "Iter 62720, Minibatch Loss= 0.238659, Training Accuracy= 0.92969\n",
      "Iter 64000, Minibatch Loss= 0.123625, Training Accuracy= 0.95312\n",
      "Iter 65280, Minibatch Loss= 0.057580, Training Accuracy= 0.98438\n",
      "Iter 66560, Minibatch Loss= 0.163423, Training Accuracy= 0.95312\n",
      "Iter 67840, Minibatch Loss= 0.095371, Training Accuracy= 0.97656\n",
      "Iter 69120, Minibatch Loss= 0.143000, Training Accuracy= 0.96094\n",
      "Iter 70400, Minibatch Loss= 0.211892, Training Accuracy= 0.93750\n",
      "Iter 71680, Minibatch Loss= 0.130791, Training Accuracy= 0.96875\n",
      "Iter 72960, Minibatch Loss= 0.108199, Training Accuracy= 0.97656\n",
      "Iter 74240, Minibatch Loss= 0.114628, Training Accuracy= 0.96094\n",
      "Iter 75520, Minibatch Loss= 0.053271, Training Accuracy= 0.99219\n",
      "Iter 76800, Minibatch Loss= 0.090962, Training Accuracy= 0.96094\n",
      "Iter 78080, Minibatch Loss= 0.106695, Training Accuracy= 0.96094\n",
      "Iter 79360, Minibatch Loss= 0.081046, Training Accuracy= 0.97656\n",
      "Iter 80640, Minibatch Loss= 0.091168, Training Accuracy= 0.96875\n",
      "Iter 81920, Minibatch Loss= 0.111013, Training Accuracy= 0.96875\n",
      "Iter 83200, Minibatch Loss= 0.085217, Training Accuracy= 0.97656\n",
      "Iter 84480, Minibatch Loss= 0.057066, Training Accuracy= 0.99219\n",
      "Iter 85760, Minibatch Loss= 0.081549, Training Accuracy= 0.96875\n",
      "Iter 87040, Minibatch Loss= 0.057460, Training Accuracy= 0.99219\n",
      "Iter 88320, Minibatch Loss= 0.128027, Training Accuracy= 0.96094\n",
      "Iter 89600, Minibatch Loss= 0.096195, Training Accuracy= 0.96875\n",
      "Iter 90880, Minibatch Loss= 0.054075, Training Accuracy= 0.98438\n",
      "Iter 92160, Minibatch Loss= 0.058814, Training Accuracy= 0.97656\n",
      "Iter 93440, Minibatch Loss= 0.076994, Training Accuracy= 0.96875\n",
      "Iter 94720, Minibatch Loss= 0.129472, Training Accuracy= 0.98438\n",
      "Iter 96000, Minibatch Loss= 0.098506, Training Accuracy= 0.96094\n",
      "Iter 97280, Minibatch Loss= 0.100387, Training Accuracy= 0.97656\n",
      "Iter 98560, Minibatch Loss= 0.114032, Training Accuracy= 0.97656\n",
      "Iter 99840, Minibatch Loss= 0.065218, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.992188\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    # [outputs' size is (?, 28, 128), we want the last element, with index 27\n",
    "    # size of last_output is then (?, 128)\n",
    "    last_output = outputs[:, outputs.get_shape()[1] - 1, :]\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(last_output, weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [batch_size, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [batch_size, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, n_steps, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "            \n",
    "    # Get lstm cell output\n",
    "    outputs,states = tf.nn.dynamic_rnn(lstm_cell, x, n_steps)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension must be 2 but is 3 for 'transpose_40' (op: 'Transpose') with input shapes: [128,28], [3].",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-75442de274fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-95dc5419cab5>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(x, weights, biases)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Get lstm cell output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Linear activation, using rnn inner loop last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])\n\u001b[0;32m--> 789\u001b[0;31m                        for input_ in flat_input)\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m   \u001b[0mparallel_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((input_,))\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])\n\u001b[0;32m--> 789\u001b[0;31m                        for input_ in flat_input)\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m   \u001b[0mparallel_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m   3654\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3655\u001b[0m   \"\"\"\n\u001b[0;32m-> 3656\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transpose\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3657\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    757\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    758\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2240\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1615\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1687487/miniconda2/envs/mlp/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension must be 2 but is 3 for 'transpose_40' (op: 'Transpose') with input shapes: [128,28], [3]."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "pred = LSTM(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print \"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
