{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/disk/scratch/mlp/miniconda2/bin/python\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Utilities\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #check necessary environment variables are defined\n",
    "# assert 'MLP_DATA_DIR' in os.environ, 'An environment variable MLP_DATA_DIR must be set to the path containing MLP data before running script.'\n",
    "# # assert 'OUTPUT_DIR' in os.environ, 'An environment variable OUTPUT_DIR must be set to the path to write output to before running script.'\n",
    "# save_point = '/home/s1687487/0304/0/exp/' #'/home/s1687487/0228/0/exp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "# batch_size = 500\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "batch_size = 128\n",
    "from mlp.data_providers import MSD10GenreDataProvider, MSD25GenreDataProvider\n",
    "train_data = MSD10GenreDataProvider('train', batch_size = batch_size, max_num_batches=5)\n",
    "valid_data = MSD10GenreDataProvider('valid', batch_size = batch_size, max_num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "# training_iters = 100000\n",
    "training_epochs = 5\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 25 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 120 # timesteps\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiments():\n",
    "    for n_layers in n_layers_list:\n",
    "        for n_hidden in n_hidden_list:\n",
    "            # tf Graph input\n",
    "            x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "            y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "            # Define weights\n",
    "            weights = {\n",
    "                'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "            }\n",
    "            biases = {\n",
    "                'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "            }\n",
    "\n",
    "            tf.add_to_collection('vars', weights['out'])\n",
    "            tf.add_to_collection('vars', biases['out'])\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            def Network(x, weights, biases): # Fully BPTT\n",
    "                # Define a lstm cell with tensorflow\n",
    "                cell = tf.nn.rnn_cell.GRUCell(n_hidden)            \n",
    "                stacked_cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell] * n_layers)\n",
    "\n",
    "                outputs, states = tf.nn.dynamic_rnn(stacked_cell, x, dtype=tf.float32)\n",
    "                # [outputs' size is (?, n_steps, n_hidden), we want the last element, with index 120-1 for MSD\n",
    "                # size of last_output is then (?, n_hidden)\n",
    "\n",
    "            #     print 'state_size = ', lstm_cell.state_size\n",
    "\n",
    "                last_output = outputs[:, outputs.get_shape()[1] - 1, :]\n",
    "                # Linear activation, using rnn inner loop last output\n",
    "                return tf.matmul(last_output, weights['out']) + biases['out']\n",
    "\n",
    "            pred = Network(x, weights, biases)\n",
    "\n",
    "            # Define loss and optimizer\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "            # Evaluate model\n",
    "            correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "            # Initializing the variables\n",
    "            init = tf.global_variables_initializer()\n",
    "\n",
    "            # Performance pickles\n",
    "            err_tr = np.zeros(training_epochs)\n",
    "            acc_tr = np.zeros(training_epochs)\n",
    "            err_val = np.zeros(training_epochs)\n",
    "            acc_val = np.zeros(training_epochs)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                print(\"Optimization Starts! Dim(hidden)={0:d}, n_layers={1:d}\"\n",
    "                      .format(n_hidden,n_layers))\n",
    "                sess.run(init) #initial run\n",
    "\n",
    "                for e in range(training_epochs):                              \n",
    "                    if e == 0:\n",
    "                        start = time.time()\n",
    "                        num_batches_tr = 0\n",
    "                        num_batches_val = 0\n",
    "\n",
    "                    running_error = 0.\n",
    "                    running_accuracy = 0.\n",
    "                    for input_batch, target_batch in train_data:\n",
    "                        if e == 0:\n",
    "                            num_batches_tr += 1\n",
    "                        input_batch = input_batch.reshape((batch_size,n_steps,n_input))\n",
    "\n",
    "                        _, batch_error, batch_acc = sess.run(\n",
    "                            [optimizer, cost, accuracy], \n",
    "                            feed_dict={x: input_batch, y: target_batch})\n",
    "                        running_error += batch_error\n",
    "                        running_accuracy += batch_acc\n",
    "            #             if num_batches_tr % 100 == 0:\n",
    "            #                 print('{0:02d}th batch: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "            #                       .format(num_batches_tr,running_error/num_batches_tr,running_accuracy/num_batches_tr))                      \n",
    "                    running_error /= num_batches_tr\n",
    "                    err_tr[e] = running_error\n",
    "                    running_accuracy /= num_batches_tr\n",
    "                    acc_tr[e] = running_accuracy\n",
    "\n",
    "                    if ((e+1) % display_step == 0) or (e == 0):\n",
    "                        end = time.time()\n",
    "                        print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f} ,,, taking {3:.1f}(sec)'\n",
    "                              .format(e + 1, running_error, running_accuracy, end-start))\n",
    "\n",
    "                        start = time.time()            \n",
    "\n",
    "                        valid_error = 0.\n",
    "                        valid_accuracy = 0.\n",
    "                        for input_batch, target_batch in valid_data:\n",
    "                            if e == 0:\n",
    "                                num_batches_val += 1\n",
    "                            input_batch = input_batch.reshape((batch_size,n_steps,n_input))\n",
    "\n",
    "                            batch_error, batch_acc = sess.run(\n",
    "                                [cost, accuracy], \n",
    "                                feed_dict={x: input_batch, y: target_batch})\n",
    "                            valid_error += batch_error\n",
    "                            valid_accuracy += batch_acc\n",
    "                        valid_error /= num_batches_val\n",
    "                        err_val[e] = valid_error\n",
    "                        valid_accuracy /= num_batches_val\n",
    "                        acc_val[e] = valid_accuracy\n",
    "\n",
    "                        end = time.time()\n",
    "                        print('                 err(valid)={0:.2f} acc(valid)={1:.2f} ,,, taking {2:.1f}(sec) '\n",
    "                               .format(valid_error, valid_accuracy, end-start))\n",
    "\n",
    "                        start = time.time()\n",
    "\n",
    "                #Save model - save session\n",
    "                sname = 'params_lstm_h' + str(n_hidden) +'_ly' + str(n_layers)\n",
    "                saver.save(sess, sname)\n",
    "    #             saver.save(sess, save_point+sname)\n",
    "                #...performance as well - pickle\n",
    "                lstm_prf = {\"err_tr\": err_tr, \"err_val\": err_val, \"acc_tr\": acc_tr, \"acc_val\": acc_val}\n",
    "                fname = \"lstm_performances_h\" + str(n_hidden) +'_ly' + str(n_layers) + \".p\" \n",
    "                pickle.dump(lstm_prf, open(fname,\"wb\"))\n",
    "    #             pickle.dump(lstm_prf, open(save_point+fname,\"wb\"))\n",
    "\n",
    "                #Reset the data\n",
    "                train_data.reset()\n",
    "                valid_data.reset()\n",
    "                print ''\n",
    "\n",
    "            #Reset the graph per each iteration\n",
    "            tf.reset_default_graph()\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Starts! Dim(hidden)=5, n_layers=1\n",
      "End of epoch 01: err(train)=2.98 acc(train)=0.07 ,,, taking 0.3(sec)\n",
      "                 err(valid)=3.09 acc(valid)=0.10 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=10, n_layers=1\n",
      "End of epoch 01: err(train)=3.24 acc(train)=0.10 ,,, taking 0.3(sec)\n",
      "                 err(valid)=3.18 acc(valid)=0.11 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=20, n_layers=1\n",
      "End of epoch 01: err(train)=3.76 acc(train)=0.09 ,,, taking 0.4(sec)\n",
      "                 err(valid)=3.68 acc(valid)=0.12 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=30, n_layers=1\n",
      "End of epoch 01: err(train)=4.11 acc(train)=0.10 ,,, taking 0.5(sec)\n",
      "                 err(valid)=3.72 acc(valid)=0.16 ,,, taking 0.1(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=50, n_layers=1\n",
      "End of epoch 01: err(train)=3.84 acc(train)=0.13 ,,, taking 0.8(sec)\n",
      "                 err(valid)=3.54 acc(valid)=0.12 ,,, taking 0.1(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=5, n_layers=2\n",
      "End of epoch 01: err(train)=2.91 acc(train)=0.10 ,,, taking 0.4(sec)\n",
      "                 err(valid)=2.80 acc(valid)=0.09 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=10, n_layers=2\n",
      "End of epoch 01: err(train)=3.85 acc(train)=0.08 ,,, taking 0.4(sec)\n",
      "                 err(valid)=3.52 acc(valid)=0.10 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=20, n_layers=2\n",
      "End of epoch 01: err(train)=3.14 acc(train)=0.12 ,,, taking 0.4(sec)\n",
      "                 err(valid)=3.18 acc(valid)=0.14 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=30, n_layers=2\n",
      "End of epoch 01: err(train)=2.98 acc(train)=0.10 ,,, taking 0.5(sec)\n",
      "                 err(valid)=2.89 acc(valid)=0.11 ,,, taking 0.1(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=50, n_layers=2\n",
      "End of epoch 01: err(train)=3.21 acc(train)=0.10 ,,, taking 0.9(sec)\n",
      "                 err(valid)=2.81 acc(valid)=0.11 ,,, taking 0.1(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=5, n_layers=3\n",
      "End of epoch 01: err(train)=2.67 acc(train)=0.07 ,,, taking 0.4(sec)\n",
      "                 err(valid)=2.74 acc(valid)=0.05 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=10, n_layers=3\n",
      "End of epoch 01: err(train)=2.67 acc(train)=0.13 ,,, taking 0.5(sec)\n",
      "                 err(valid)=2.64 acc(valid)=0.14 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=20, n_layers=3\n",
      "End of epoch 01: err(train)=2.84 acc(train)=0.10 ,,, taking 0.5(sec)\n",
      "                 err(valid)=2.67 acc(valid)=0.09 ,,, taking 0.0(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=30, n_layers=3\n",
      "End of epoch 01: err(train)=3.22 acc(train)=0.13 ,,, taking 0.6(sec)\n",
      "                 err(valid)=2.86 acc(valid)=0.13 ,,, taking 0.1(sec) \n",
      "\n",
      "Optimization Starts! Dim(hidden)=50, n_layers=3\n",
      "End of epoch 01: err(train)=3.06 acc(train)=0.10 ,,, taking 1.0(sec)\n",
      "                 err(valid)=2.64 acc(valid)=0.17 ,,, taking 0.1(sec) \n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "n_hidden_list = [5,10,20,30,50] # dim(hidden layer) <- run this with 10 and 50 after this...\n",
    "n_layers_list = [1,2,3]\n",
    "experiments()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
